# Database Configuration
# Get this from your Neon project dashboard
DATABASE_URL="postgresql://username:password@host.neon.tech/dbname?sslmode=require"

# Ollama Configuration
# Local Ollama endpoint (default is localhost:11434)
OLLAMA_HOST=http://localhost:11434

# Models to use
OLLAMA_EMBED_MODEL=nomic-embed-text
OLLAMA_LLM_MODEL=phi3.5

# API Keys
# Groq API for LLM inference
GROQ_API_KEY=your_groq_api_key_here

# LLM Cascade Strategy
# "simple" = Gemini -> Ollama (preserves Groq rate limits, default)
# "extended" = Gemini -> Groq -> Ollama (more resilient, uses Groq quota)
LLM_CASCADE_STRATEGY=simple

# Pipeline Configuration
# Batch size for processing sections
PIPELINE_BATCH_SIZE=1000

# Loader Configuration
# Batch size for database inserts
LOADER_BATCH_SIZE=500

# Next.js Configuration (for apps/web/.env.local)
# Copy DATABASE_URL from above
NEXT_PUBLIC_APP_URL=http://localhost:3000
